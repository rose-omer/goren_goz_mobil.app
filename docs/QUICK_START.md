# ğŸš€ VLM HÄ±zlÄ± BaÅŸlangÄ±Ã§

## 5 DakikalÄ±k Kurulum

### Terminal 1ï¸âƒ£ - Ollama Sunucusu
```powershell
ollama serve
```
Port 11434'te dinlemeli

### Terminal 2ï¸âƒ£ - Backend API
```powershell
cd backend
python main.py
```
Port 8000'de Ã§alÄ±ÅŸmalÄ±

### Terminal 3ï¸âƒ£ - Test
```powershell
python test_vlm.py
```

## ğŸ“Š Beklenen SonuÃ§

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  VLM Ä°NTEGRASYON TESTÄ° SONUÃ‡LARI
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ… Test 1: VLM BaÄŸlantÄ±sÄ±
   Ollama server'a baÅŸarÄ±yla baÄŸlandÄ±
   Server: http://localhost:11434
   Model: smolvlm

âœ… Test 2: Resim Analizi
   Ã–rnek resim analiz edildi
   SonuÃ§: [30 satÄ±r TÃ¼rkÃ§e analiz]

âœ… Test 3: Nesne Tespiti ile
   YOLO detections: 5 nesne bulundu
   Analiz: [TÃ¼rkÃ§e baÄŸlam metni]

âœ… Test 4: HazÄ±r Sorular
   6 soruda yanÄ±t alÄ±ndÄ±
   TÃ¼mÃ¼ baÅŸarÄ±lÄ±

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Toplam: 4/4 TEST GEÃ‡TÄ° âœ¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

## ğŸ”§ API Endpoints

```bash
# BaÄŸlam sorgusu (resim + soru)
curl -X POST http://localhost:8000/api/ask_context \
  -F "image=@your_image.jpg" \
  -F "question=Hangi taraftan tehlike var?"

# HazÄ±r sorular listesi
curl http://localhost:8000/api/preset_questions
```

## ğŸ› ï¸ Ayarlar (config/config.yaml)

```yaml
vlm:
  enabled: true
  server_url: "http://localhost:11434"
  timeout: 30
  max_retries: 2
  model_name: "smolvlm"
  n_predict: 100
  temperature: 0.7
```

## âŒ Sorun mu var?

Åu dosyayÄ± oku: [WINDOWS_VLM_SETUP.md](WINDOWS_VLM_SETUP.md)

---

**HazÄ±rsa ÅŸimdi baÅŸla!** ğŸ¯
