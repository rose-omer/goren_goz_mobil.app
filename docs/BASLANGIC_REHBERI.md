# ğŸš€ BaÅŸlangÄ±Ã§ Rehberi - AdÄ±m AdÄ±m Kurulum

Bu rehber, uygulamayÄ± sÄ±fÄ±rdan Ã§alÄ±ÅŸtÄ±rmak iÃ§in gereken tÃ¼m adÄ±mlarÄ± iÃ§erir.

---

## ADIM 1: llama.cpp Ä°ndir (CPU Versiyonu)

### 1.1 Ä°ndirme

1. [llama.cpp Releases](https://github.com/ggerganov/llama.cpp/releases) sayfasÄ±na git
2. En son release'i bul (Ã¶rn: `b4295` gibi bir numara)
3. **CPU versiyonunu** indir:
   - Dosya adÄ±: `llama-b4295-bin-win-avx2-x64.zip` (numara deÄŸiÅŸebilir)
   - âš ï¸ CUDA/GPU versiyonunu ALMA, senin ekran kartÄ±n yok

### 1.2 Ã‡Ä±kartma

1. ZIP dosyasÄ±nÄ± `C:\llama.cpp\` klasÃ¶rÃ¼ne Ã§Ä±kart
2. KlasÃ¶r yapÄ±sÄ± ÅŸÃ¶yle olmalÄ±:
   ```
   C:\llama.cpp\
   â”œâ”€â”€ bin\
   â”‚   â”œâ”€â”€ llama-server.exe
   â”‚   â”œâ”€â”€ llama-cli.exe
   â”‚   â””â”€â”€ ...
   â””â”€â”€ README.md
   ```

---

## ADIM 2: SmolVLM Modelini Ä°ndir

### 2.1 Otomatik Ä°ndirme (Ã–nerilen)

Terminal aÃ§ ve ÅŸunu Ã§alÄ±ÅŸtÄ±r:

```powershell
cd C:\llama.cpp\bin
.\llama-server.exe -hf ggml-org/SmolVLM-500M-Instruct-GGUF
```

- Model otomatik indirilecek (~500MB)
- Ä°ndirme yeri: `C:\Users\admin\.cache\llama.cpp\`
- Ä°lk seferde 5-10 dakika sÃ¼rebilir

Server baÅŸladÄ±ÄŸÄ±nda ÅŸunu gÃ¶receksin:
```
llama server listening at http://localhost:8080
```

**Server Ã§alÄ±ÅŸÄ±yor demektir!** Åimdilik KAPAT (Ctrl+C).

---

## ADIM 3: Backend Dependencies YÃ¼kle

### 3.1 Terminal AÃ§

PowerShell veya CMD aÃ§.

### 3.2 Proje KlasÃ¶rÃ¼ne Git

```powershell
cd C:\Users\admin\Desktop\goren_goz_mobil.app\backend
```

### 3.3 Virtual Environment Aktif Et (Varsa)

EÄŸer venv varsa:
```powershell
.\.venv\Scripts\activate
```

Yoksa devam et.

### 3.4 Yeni Paketleri YÃ¼kle

```powershell
pip install requests aiohttp
```

Hepsi yÃ¼klendiÄŸinde:
```
Successfully installed requests-2.31.0 aiohttp-3.9.0
```

---

## ADIM 4: Mobil UygulamayÄ± Telefona YÃ¼kle

### 4.1 Telefonu Bilgisayara BaÄŸla

- USB kabloyla baÄŸla
- Telefonda **Developer Options** aÃ§Ä±k olmalÄ±
- **USB Debugging** aktif olmalÄ±

### 4.2 Flutter Proje KlasÃ¶rÃ¼ne Git

```powershell
cd C:\Users\admin\Desktop\goren_goz_mobil.app\mobile_app
```

### 4.3 Telefon BaÄŸlantÄ±sÄ±nÄ± Kontrol Et

```powershell
flutter devices
```

Ã‡Ä±ktÄ±da telefonunu gÃ¶rmelisin:
```
SM G996B (mobile) â€¢ abc123 â€¢ android-arm64
```

### 4.4 Backend IP Adresini Ayarla

BilgisayarÄ±nÄ±n IP adresini Ã¶ÄŸren:

```powershell
ipconfig
```

IPv4 adresini not et (Ã¶rn: `192.168.1.100`)

**constants.dart dosyasÄ±nÄ± dÃ¼zenle:**

Dosya yolu: `mobile_app\lib\utils\constants.dart`

```dart
static const String apiUrl = 'http://192.168.1.100:8000'; // IP'ni buraya yaz
```

### 4.5 UygulamayÄ± YÃ¼kle ve Ã‡alÄ±ÅŸtÄ±r

```powershell
flutter run --release
```

- `--release` daha hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r
- Ä°lk seferde 5-10 dakika sÃ¼rebilir
- Uygulama telefona yÃ¼klenip aÃ§Ä±lacak

---

## ADIM 5: Her Åeyi BaÅŸlat (SÄ±rayla)

### 5.1 Terminal 1: llama-server (VLM)

```powershell
cd C:\llama.cpp\bin
.\llama-server.exe -hf ggml-org/SmolVLM-500M-Instruct-GGUF
```

**Ã‡Ä±ktÄ±:**
```
llama server listening at http://localhost:8080
```

âœ… Bu terminal aÃ§Ä±k kalmalÄ±!

---

### 5.2 Terminal 2: Backend

Yeni bir terminal aÃ§:

```powershell
cd C:\Users\admin\Desktop\goren_goz_mobil.app\backend
.\.venv\Scripts\activate  # Varsa
python main.py
```

**Ã‡Ä±ktÄ±:**
```
âœ“ VLM server is ready
INFO: Uvicorn running on http://0.0.0.0:8000
```

âœ… Bu terminal de aÃ§Ä±k kalmalÄ±!

---

### 5.3 Telefonda UygulamayÄ± Kullan

1. **Kamera ekranÄ± aÃ§Ä±lÄ±r**
2. **"Soru Sor" butonuna tÄ±kla** (ortadaki extended buton)
3. **Bir soru seÃ§:** Ã–rn: "Ã–nÃ¼mde ne var?"
4. **Bekle** (3-5 saniye - CPU'da yavaÅŸ)
5. **Cevap gelir ve sesli okunur!** ğŸ”Š

---

## Ã–zet SÄ±rasÄ±

```
SIRA 1: llama-server baÅŸlat (Terminal 1)
SIRA 2: Backend baÅŸlat (Terminal 2)
SIRA 3: Telefonda uygulamayÄ± kullan
```

---

## Sorun Giderme

### "VLM sunucusu Ã§alÄ±ÅŸmÄ±yor olabilir"

âœ… **Ã‡Ã¶zÃ¼m:** llama-server Ã§alÄ±ÅŸÄ±yor mu kontrol et (Terminal 1)

Browser'da aÃ§: `http://localhost:8080`

Bir UI gÃ¶rmelisin.

---

### "BaÄŸlantÄ± hatasÄ±"

âœ… **Ã‡Ã¶zÃ¼m:** 

1. Backend Ã§alÄ±ÅŸÄ±yor mu? (Terminal 2)
2. Telefon ve PC aynÄ± WiFi'de mi?
3. `constants.dart` dosyasÄ±nda IP doÄŸru mu?

Test iÃ§in browser'da aÃ§: `http://192.168.1.100:8000/health`

---

### Ã‡ok YavaÅŸ (5+ saniye)

âœ… **Normal:** CPU'da SmolVLM yavaÅŸtÄ±r. Ekran kartÄ± olsaydÄ± 10x hÄ±zlÄ± olurdu.

**Beklenen sÃ¼re:**
- CPU: 3-5 saniye
- GPU: 0.5-1 saniye

---

## Ä°lk Test

Backend baÅŸlattÄ±ktan sonra bu komutu Ã§alÄ±ÅŸtÄ±r:

```powershell
curl http://localhost:8000/health
```

**Beklenen yanÄ±t:**
```json
{
  "status": "healthy",
  "vlm": {
    "server_ready": true
  }
}
```

`"server_ready": true` ise her ÅŸey hazÄ±r! ğŸ‰

---

## Notlar

- âš ï¸ llama-server ve backend **her zaman** Ã§alÄ±ÅŸmalÄ±
- ğŸ’¡ BilgisayarÄ± kapatÄ±rsan, tekrar ADIM 5'i yap
- ğŸ”‡ Ä°lk Ã§alÄ±ÅŸtÄ±rmada model yÃ¼klenir, biraz uzun sÃ¼rer (normal)
- ğŸ“± Telefon ve PC **aynÄ± WiFi**'de olmalÄ±

---

**HazÄ±rsÄ±n!** Sorular olursa sor. ğŸš€
